{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## 순환 신경망 제작, 텍스트 분류 "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 불러오기 \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb # 인터넷 영화 데이터베이스(Internet Movie Database, 영화 리뷰 데이터). \n",
    "\n",
    "# 리뷰가 긍정적인지 부정적인지 판단하는 모델을 만들 것\n",
    "\n",
    "(x_train_all, y_train_all), (x_test, y_test) = imdb.load_data(skip_top=20, num_words=100) # imdb 데이터셋은 리뷰에 포함된 8만개 이상의 단어를 고유한 정수로 미리 바꿔놓음\n",
    "# skip_top : 가장 많이 등장한 단어들 중 건너뛸 단어의 개수를 지정. 예를 들면 a, the, is같은 애들. 얘들은 많이 나오는데 분석에는 유용한 애들이 아니니 건너뛴다. \n",
    "# num_words : 훈련에 사용될 단어의 개수. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_all.shape, y_train_all.shape) # 크기 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2, 2, 22, 2, 43, 2, 2, 2, 2, 65, 2, 2, 66, 2, 2, 2, 36, 2, 2, 25, 2, 43, 2, 2, 50, 2, 2, 2, 35, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 39, 2, 2, 2, 2, 2, 2, 38, 2, 2, 2, 2, 50, 2, 2, 2, 2, 2, 2, 22, 2, 2, 2, 2, 2, 22, 71, 87, 2, 2, 43, 2, 38, 76, 2, 2, 2, 2, 22, 2, 2, 2, 2, 2, 2, 2, 2, 2, 62, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 66, 2, 33, 2, 2, 2, 2, 38, 2, 2, 25, 2, 51, 36, 2, 48, 25, 2, 33, 2, 22, 2, 2, 28, 77, 52, 2, 2, 2, 2, 82, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 36, 71, 43, 2, 2, 26, 2, 2, 46, 2, 2, 2, 2, 2, 2, 88, 2, 2, 2, 2, 98, 32, 2, 56, 26, 2, 2, 2, 2, 2, 2, 2, 22, 21, 2, 2, 26, 2, 2, 2, 30, 2, 2, 51, 36, 28, 2, 92, 25, 2, 2, 2, 65, 2, 38, 2, 88, 2, 2, 2, 2, 2, 2, 2, 2, 32, 2, 2, 2, 2, 2, 32]\n"
     ]
    }
   ],
   "source": [
    "# 샘플 확인\n",
    "print(x_train_all[0]) # 숫자만 존나게 나옴. 이 정수들은 영단어를 고유한 정수에 일대일 대응한 것. 이를 BoW(Bag of Word) 혹은 어휘 사전이라 부름. \n",
    "# 2는 어휘사전에 없는 단어를 의미함. 왜 2만 존나게 떴냐면 앞서 데이터를 불러올 때 가장 많이 등장하는 영단어를 20개나 스킵한데다 훈련에 사용할 단어도 100개 뿐이기 때문. 그래서 사전에 없는 영단어가 많다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쓸모없는 단어 지우기 \n",
    "# 0과 1은 패딩이고 2는 어휘사전에 없는 단어(=훈련에 쓰지 않는 단어)를 의미하기 때문에 지워준다. \n",
    "for i in range(len(x_train_all)):\n",
    "    x_train_all[i] = [w for w in x_train_all[i] if w > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[22, 43, 65, 66, 36, 25, 43, 50, 35, 39, 38, 50, 22, 22, 71, 87, 43, 38, 76, 22, 62, 66, 33, 38, 25, 51, 36, 48, 25, 33, 22, 28, 77, 52, 82, 36, 71, 43, 26, 46, 88, 98, 32, 56, 26, 22, 21, 26, 30, 51, 36, 28, 92, 25, 65, 38, 88, 32, 32]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_all[0]) # 의미 있는 단어들만 등장. 추측상 단어에 해당하는 번호들의 모음이 아닐까 싶다. 인덱스 번호 뭐 그런거겠지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "# 어휘 사전 내려받기\n",
    "# 훈련 세트를 영단어로 바꿔보자. \n",
    "word_to_index = imdb.get_word_index()\n",
    "word_to_index['movie'] # movie에 해당하는 키 값을 출력 -> 17이라고 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "film just story really they you just there an from so there film film were great just so much film would really at so you what they if you at film have been good also they were just are out because them all up are film but are be what they have don't you story so because all all "
     ]
    }
   ],
   "source": [
    "# 훈련 세트의 정수를 영단어로 변환 \n",
    "# 훈련 세트에 있는 정수는 3 이상부터 영단어를 의미한다.(0, 1은 패딩이고 2는 사용하지 않는 단어) 그래서 3을 뺀 값을 인덱스로 써야한다. \n",
    "index_to_word = {word_to_index[k] : k for k in word_to_index} # 일반적인 문자열 배열로 바꿔주는 듯. \n",
    "\n",
    "for w in x_train_all[0]:\n",
    "    print(index_to_word[w-3], end=' ') # 단어들 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "59 32\n"
     ]
    }
   ],
   "source": [
    "# 훈련 샘플의 길이 확인\n",
    "print(len(x_train_all[0]), len(x_train_all[1])) # 샘플의 길이가 차이가 어느정도 있다. 이러면 훈련 시키기가 어렵다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1 0 0 1 0 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# 타깃 데이터 확인\n",
    "# 리뷰가 긍정인지 부정인지 확인하는 모델이니 긍정, 부정의 이진 분류 문제를 다룬다고 볼 수 있다. 그래서 타깃 데이터의 값들은 0 아니면 1이다. \n",
    "print(y_train_all[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 세트 준비\n",
    "# 훈련 데이터셋 중 일부만 떼서 검증 셋으로 활용 \n",
    "np.random.seed(42) # 교재랑 같은 값이 나온다는거 확인시켜줄려고 랜덤 상수 고정\n",
    "random_index = np.random.permutation(25000) # 데이터 섞어주기. '단어들의 모음'을 섞으니 문제 없다. \n",
    "\n",
    "x_train = x_train_all[random_index[:20000]]\n",
    "y_train = y_train_all[random_index[:20000]]\n",
    "x_val = x_train_all[random_index[20000:]]\n",
    "y_val = y_train_all[random_index[20000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 길이 맞추기\n",
    "# 일정 길이를 정해놓고 길면 왼쪽을 짜르고(0~) 짧으면 왼쪽을 0으로 채운다. 만약 오른쪽으로 0으로 채운다면 순환 레이어의 역방향 계산 특성상 이전 연산의 출력값을 꼬리를 무는 방식으로 사용하기 때문에 좋은 성능을 기대하기 힘들 것이다.(꼬리를 물다가 미자막에 0이 나오는 방식이 더 낫다)\n",
    "\n",
    "# 텐서플로우로 샘플의 길이 맞추기 \n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "maxlen = 100 # 샘플 길이를 100으로 맞춤\n",
    "x_train_seq = sequence.pad_sequences(x_train, maxlen=maxlen) # 100보다 작으면 채우고 길면 자르고\n",
    "x_val_seq = sequence.pad_sequences(x_val, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(20000, 100) (5000, 100)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_seq.shape, x_val_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  0  0  0  0  0  0  0  0  0  0  0  0  0  0 35 40 27 28 40 22 83 31 85 45\n 24 23 31 70 31 76 30 98 32 22 28 51 75 56 30 33 97 53 38 46 53 74 31 35\n 23 34 22 58]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_seq[0]) # 부족한 크기만큼 왼쪽에 0으로 채웠다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련을 위해 데이터 전처리 -> 정수 데이터(입력 데이터)를 원-핫 인코딩. 생각해보니 데이터 전처리는 입력 데이터만 하면 되는구나. 허허...\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 길이 맞춰놓은 애들 원-핫 인코딩 처리\n",
    "x_train_onehot = to_categorical(x_train_seq)\n",
    "x_val_onehot = to_categorical(x_val_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(20000, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_onehot.shape) # 크기 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "800000000\n"
     ]
    }
   ],
   "source": [
    "print(x_train_onehot.nbytes) # 용량 확인. 800000000 -> 800 * 1,000,000 => 약 760MB라고 한다. 왜 760MB지? 진수가 달라서 그런가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 클래스 작성 \n",
    "\n",
    "class RecurrentNetwork:\n",
    "    def __init__(self, n_cells = 10, batch_size = 32, learning_rate = 0.1):\n",
    "\n",
    "        self.n_cells = n_cells # 셀 개수(유닛 개수라 생각하면 된다. 실제로 같은 의미를 가진다.)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.w1h = None # 은닉 상태에 대한 가중치(=이전 연산의 출력값에 대한 가중치)\n",
    "        self.w1x = None # 입력에 대한 가중치\n",
    "        self.b1 = None\n",
    "        self.w2 = None\n",
    "        self.b2 = None\n",
    "        self.h = None # 순환층의 활성화 출력\n",
    "        self.losses = [] # 훈련 손실\n",
    "        self.val_losses = [] # 검증 손실\n",
    "        self.lr = learning_rate # 학습률\n",
    "\n",
    "    def init_weights(self, n_features, n_classes): # 순환 레이어의 가중치들은 직교 행렬 방식으로 초기화. 직교 행렬 초기화 방식은 순환 셀에서 은닉 상태를 위한 가중치가 반복해서 곱해질 때 너무 커지거나 작아지지 않도록 만들어준다. \n",
    "        orth_init = tf.initializers.Orthogonal() # Orthogonal()제공\n",
    "        glolot_init = tf.initializers.GlorotUniform()\n",
    "\n",
    "        self.w1h = orth_init((self.n_cells, self.n_cells)).numpy() # (셀 개수, 셀 개수) \n",
    "        self.w1x = glolot_init((n_features, self.n_cells)).numpy() # (특성 개수, 셀 개수)\n",
    "        self.b1 = np.zeros(self.n_cells) # 은닉층의 크기\n",
    "        self.w2 = glolot_init((self.n_cells, n_classes)).numpy() # (셀 개수, 클래스 개수)\n",
    "        self.b2 = np.zeros(n_classes)\n",
    "\n",
    "    def forpass(self, x):# 정방향 계산\n",
    "        self.h = [np.zeros((x.shape[0], self.n_cells))] # 은닉 상태 초기화\n",
    "        seq = np.swapaxes(x, 0, 1) # 입력 x의 첫 번째 배치 차원과 두 번째 타임 스탭 차원을 변경. 왜 이걸 하는걸까?\n",
    "        # 왜 이걸 하냐면 원래 데이터셋은 (샘플, 타임스탭, 원-핫-인코딩)이라 그대로 정방향 계산을 할 경우 한 샘플의 모든 타임스텝을 한 번에 계산해버린다. \n",
    "        # 허나 이는 우리가 원하는 방식이 아니다. 우리는 한 타임스탭씩 계산하길 원한다. 그래서 '모든 샘플'을 타임 스탭 단위로 연산하기 위해 (타임스탭, 샘플, 원-핫-인코딩)으로 바꾼 것이다. \n",
    "        # 바꾼 이후 정방향 계산\n",
    "        for x in seq:\n",
    "            z1 = np.dot(x, self.w1x) + np.dot(self.h[-1], self.w1h) + self.b1 # 순환 레이어 선형계산\n",
    "            h = np.tanh(z1)\n",
    "            self.h.append(h)\n",
    "            z2 = np.dot(h, self.w2) + self.b2 # 완전 연결 레이어 선형계산\n",
    "        return z2\n",
    "    \n",
    "    def backprop(self, x, err): # 역방향 계산. 역방향 계산 역시 타임스탭과 미니 배치의 차원을 맞바꿈.\n",
    "        m = len(x) # 입력 데이터 개수\n",
    "        \n",
    "        # 출력층의 가중치, 절편에 대한 공식\n",
    "        w2_grad = np.dot(self.h[-1].T, err) / m # 완전 연결층에서 그레디언트\n",
    "        b2_grad = np.sum(err)/ m # 절편에 대한 그래디언트\n",
    "        # 배치 차원과 타임 스태프 차원을 맞바꿈\n",
    "        seq = np.swapaxes(x, 0, 1)\n",
    "        \n",
    "        # 첫번 째 층의 그래디언트\n",
    "        w1h_grad = w1x_grad = b1_grad = 0\n",
    "        # 이론에서 배웠듯 순환 레이어 직전까지 그레디언트를 계산하고 err_to_cell이라고 정의\n",
    "        err_to_cell = np.dot(err, self.w2.T) * (1-self.h[-1] ** 2)\n",
    "        ## 맨 처음 출력값까지 거슬러 올라가며 그레디언트 전파\n",
    "        for x, h in zip(seq[::-1][:10], self.h[:-1][::-1][:10]): # -1을 넣었다 -> 뒤에서부터 앞으로 돌리겠다. 식보면 알겠지만 최근 값(제일 뒤에 있는 값)에서 시작해 가장 옛날 값(제일 앞에 있는 값)까지 가기 때문에 이렇게 역으로 돌려야한다. \n",
    "            w1h_grad += np.dot(h.T, err_to_cell)\n",
    "            w1x_grad += np.dot(x.T, err_to_cell)\n",
    "            b1_grad += np.sum(err_to_cell, axis=0)\n",
    "            # 이전 타임 스텝의 셀 직전까지 다시 그레디언트 계산(꼬리의 꼬리를 물기)\n",
    "            err_to_cell = np.dot(err_to_cell, self.w1h) * (1-h ** 2)\n",
    "        \n",
    "        w1h_grad /= m\n",
    "        w1x_grad /= m\n",
    "        b1_grad /= m\n",
    "\n",
    "        return w1h_grad, w1x_grad, b1_grad, w2_grad, b2_grad\n",
    "\n",
    "    def sigmoid(self, z): # 시그모이드 활성화 함수\n",
    "        a = 1/(1+np.exp(-z))\n",
    "        return a\n",
    "\n",
    "    def fit(self, x, y, epochs = 100, x_val = None, y_val = None):\n",
    "        # 초기화 파트\n",
    "        y = y.reshape(-1, 1) # 타깃을 열 벡터(위아래로 긴거)로 바꿈\n",
    "        y_val = y_val.reshape(-1, 1)\n",
    "        np.random.seed(42) # 교재에서 예제와 같음을 보여주기 위해 사용한 함수. 실제로는 사용하지 않아도 된다. \n",
    "        self.init_weights(x.shape[2], y.shape[1]) # 은닉층과 출력층의 가중치를 초기화\n",
    "        \n",
    "        # 에포크만큼 반복(훈련 파트)\n",
    "        for i in range(epochs):\n",
    "            print('에포크', i, end=' ')\n",
    "            # 미니 배치를 순환하는 for문\n",
    "            batch_losses = []\n",
    "            for x_batch, y_batch in self.gen_batch(x, y): # gen_batch() : 전체 데이터를 받아 batch_size의 크기를 갖는 미니 배치를 만들어 반환\n",
    "                print('.', end='')\n",
    "                a = self.training(x_batch, y_batch) # 미니 배치 단위로 정방향, 역방향 계산을 수행. 출력값으로 마지막 활성화 함수의 출력을 반환\n",
    "               \n",
    "                a = np.clip(a, 1e-10, 1-1e-10) # 클리핑. 이렇게 해야 활성화 값이 튀겨서 계산에 지장이 생기는 일을 방지할 수 있다. \n",
    "                loss = np.mean(-(y_batch*np.log(a) + (1-y_batch)*np.log(1-a))) # 각 미니배치마다 발생하는 log손실과 규제 손실(reg_loss)을 차곡차곡 쌓음.\n",
    "                batch_losses.append(loss)\n",
    "            print()\n",
    "            self.losses.append(np.mean(batch_losses))\n",
    "            # 검증 세트에 대한 손실을 계산\n",
    "            self.update_val_loss(x_val, y_val)\n",
    "\n",
    "    def gen_batch(self, x, y):\n",
    "        length = len(x)\n",
    "        bins = length // self.batch_size # 미니 배치가 몇개 있는가? (//연산자는 '몫'을 의미)\n",
    "        if length % self.batch_size : # 몫으로 나누고 나머지 값이 있으면 \n",
    "            bins +=1 # 1 추가. 왜냐하면 배치사이즈로 데이터 나누고 남은 값을 버릴 수는 없으니\n",
    "        indexes = np.random.permutation(np.arange(len(x))) # 인덱스를 섞음. x길이만큼 생성된 [0, 1, 2, ...] 배열을 셔플한 걸 반환\n",
    "        #이 코드를 왜 쓰는거지? ======\n",
    "        x = x[indexes] # 이렇게 하면 x, y가 섞이나보다. \n",
    "        y = y[indexes]\n",
    "        #이 코드를 왜 쓰는거지? ======\n",
    "        for i in range(bins):\n",
    "            start = self.batch_size*i\n",
    "            end = self.batch_size*(i+1)\n",
    "            yield x[start:end], y[start:end] # yield : 반환 방식. 큰 데이터를 한 번만 반환함. 이게 뭔 뜻이냐면 전체 데이터셋 중 index의 범위가 start~end에 해당하는 배열의 일부분을 반환한다는 뜻이다. 이 때 start~end의 범위는 batch_size의 크기와 같다. 매번 포문을 진행할 때마다 batch_size크기에 해당하는 미니 배치들을 처음 데이터부터 마지막 데이터까지 순서대로 뽑아내서 반환하고 이를 이용해 훈련을 시킨다는 거다.\n",
    "    \n",
    "    def training(self, x, y):\n",
    "        m=len(x)\n",
    "        z = self.forpass(x) # 출력\n",
    "        a = self.sigmoid(z) # 활성화 함수\n",
    "        err = -(y-a) # 오차\n",
    "\n",
    "        #역전파로 그래디언트 계산\n",
    "        w1h_grad, w1x_grad, b1_grad, w2_grad, b2_grad = self.backprop(x, err)\n",
    "        # 가중치, 절편 업데이트\n",
    "        #셀의 가중치, 절편 업데이트\n",
    "        self.w1h -= self.lr * w1h_grad\n",
    "        self.w1x -= self.lr * w1x_grad\n",
    "        self.b1 -= self.lr * b1_grad\n",
    "        #출력층의 가중치, 절편 업데이트\n",
    "        self.w2 -= self.lr * w2_grad\n",
    "        self.b2 -= self.lr * b2_grad\n",
    "        return a\n",
    "\n",
    "    def predict(self,x): # 예측\n",
    "        z = self.forpass(x)\n",
    "        return z>0\n",
    "    \n",
    "    def score(self, x, y): # 성능 확인\n",
    "        # 예측값, 타깃 값 비교해 True의 비율 반환\n",
    "        return np.mean(self.predict(x) == y.reshape(-1,1))\n",
    "\n",
    "    def update_val_loss(self, x_val, y_val): # 검증 세트의 손실 업데이트\n",
    "        z = self.forpass(x_val) # 정방향 계산\n",
    "        a = self.sigmoid(z) # 활성화 함수\n",
    "        a = np.clip(a, 1e-10, 1-1e-10) # 활성화 함수 클리핑\n",
    "        # 로그 손실과 규제 손실을 더하여 리스트에 추가\n",
    "        val_loss = np.mean(-(y_val*np.log(a) + (1-y_val)*np.log(1-a)))\n",
    "        self.losses.append(val_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn = RecurrentNetwork(n_cells=32, batch_size = 32, learning_rate = 0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "에포크 0 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "에포크 1 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "에포크 2 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "에포크 3 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "에포크 4 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "에포크 5 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "에포크 6 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "에포크 7 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "에포크 8 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "에포크 9 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "에포크 10 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "에포크 11 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "에포크 12 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "에포크 13 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "에포크 14 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "에포크 15 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "에포크 16 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "에포크 17 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "에포크 18 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "에포크 19 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n"
     ]
    }
   ],
   "source": [
    "rn.fit(x_train_onehot, y_train, epochs = 20, x_val = x_val_onehot, y_val = y_val) # 타임 스텝 횟수는 모두 하이퍼 파라미터(내가 설정하는 값)이다. 그러니 반복적으로 훈련 시키며 적절한 값을 찾아야한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 378.465625 248.518125\" width=\"378.465625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-01-07T22:05:08.198349</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 378.465625 248.518125 \nL 378.465625 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 36.465625 224.64 \nL 371.265625 224.64 \nL 371.265625 7.2 \nL 36.465625 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m7d58f61fa7\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.683807\" xlink:href=\"#m7d58f61fa7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(48.502557 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"90.704786\" xlink:href=\"#m7d58f61fa7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <g transform=\"translate(87.523536 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"129.725765\" xlink:href=\"#m7d58f61fa7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 10 -->\n      <g transform=\"translate(123.363265 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"168.746744\" xlink:href=\"#m7d58f61fa7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 15 -->\n      <g transform=\"translate(162.384244 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"207.767723\" xlink:href=\"#m7d58f61fa7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 20 -->\n      <g transform=\"translate(201.405223 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"246.788702\" xlink:href=\"#m7d58f61fa7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 25 -->\n      <g transform=\"translate(240.426202 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"285.809681\" xlink:href=\"#m7d58f61fa7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 30 -->\n      <g transform=\"translate(279.447181 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"324.83066\" xlink:href=\"#m7d58f61fa7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 35 -->\n      <g transform=\"translate(318.46816 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"363.851639\" xlink:href=\"#m7d58f61fa7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 40 -->\n      <g transform=\"translate(357.489139 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mebe76adaf9\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mebe76adaf9\" y=\"198.89459\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.60 -->\n      <g transform=\"translate(7.2 202.693809)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mebe76adaf9\" y=\"163.922731\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.62 -->\n      <g transform=\"translate(7.2 167.72195)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mebe76adaf9\" y=\"128.950871\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.64 -->\n      <g transform=\"translate(7.2 132.75009)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mebe76adaf9\" y=\"93.979012\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.66 -->\n      <g transform=\"translate(7.2 97.77823)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mebe76adaf9\" y=\"59.007152\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.68 -->\n      <g transform=\"translate(7.2 62.806371)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mebe76adaf9\" y=\"24.035292\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.70 -->\n      <g transform=\"translate(7.2 27.834511)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#pfe1908b88d)\" d=\"M 51.683807 17.083636 \nL 59.488003 35.634804 \nL 67.292198 41.573998 \nL 75.096394 53.076063 \nL 82.90059 59.840159 \nL 90.704786 73.374603 \nL 98.508982 79.583499 \nL 106.313177 79.460092 \nL 114.117373 100.50869 \nL 121.921569 113.274293 \nL 129.725765 122.588024 \nL 137.529961 132.8484 \nL 145.334156 143.008543 \nL 153.138352 154.56586 \nL 160.942548 162.626121 \nL 168.746744 151.953461 \nL 176.55094 178.318014 \nL 184.355135 178.310729 \nL 192.159331 184.958003 \nL 199.963527 180.345661 \nL 207.767723 176.921076 \nL 215.571919 145.217441 \nL 223.376115 177.954777 \nL 231.18031 177.451773 \nL 238.984506 177.330859 \nL 246.788702 20.149723 \nL 254.592898 181.68688 \nL 262.397094 214.756364 \nL 270.201289 188.480282 \nL 278.005485 187.575528 \nL 285.809681 180.044169 \nL 293.613877 186.002836 \nL 301.418073 183.302406 \nL 309.222268 183.043446 \nL 317.026464 158.161645 \nL 324.83066 147.231206 \nL 332.634856 138.619157 \nL 340.439052 107.158387 \nL 348.243247 114.462897 \nL 356.047443 127.59329 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_17\"/>\n   <g id=\"patch_3\">\n    <path d=\"M 36.465625 224.64 \nL 36.465625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 371.265625 224.64 \nL 371.265625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 36.465625 224.64 \nL 371.265625 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 36.465625 7.2 \nL 371.265625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pfe1908b88d\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"36.465625\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAzbElEQVR4nO3deXhb1bX4/e+SZHlMHDu2MzjBzjyTyZkI0DTMU8JQKKEUeuGWm1Jo4faW0vaWUvrS/m65bWkLNKWBlgKXoQwN0BCgkDBmcuY4AzHO5EyOYzuJZVu2pP3+IclxHA+yLfnI0vo8Tx5HR0fS8oEsb6+9z9pijEEppVTsslkdgFJKqcjSRK+UUjFOE71SSsU4TfRKKRXjNNErpVSMc1gdQEuysrJMfn6+1WEopVSPsW7dunJjTHZLz0Vlos/Pz6ewsNDqMJRSqscQkb2tPaelG6WUinGa6JVSKsZpoldKqRiniV4ppWKcJnqllIpxmuiVUirGaaJXSqkYFzOJvq7By58/KuGzL8qtDkUppaJKVN4w1Rl2m/Dnj0sYM6A35wzLsjocpZSKGjEzok+w2/jajDw+/Pwou8tdVoejlFJRI2YSPcCC6YNx2ITnVrV6J7BScWFzaRX7K2qsDkNFiZhK9Dm9k7hswgBeLtxPTb3H6nCUssw9L23kN+99bnUYKkqElOhF5FIR2SkixSJyfwvPf19ENgb+bBURr4hkhvLacLt1Vh4n6zz8Y8PBSH+UUlHreE0DVTX1VoehokS7iV5E7MDjwGXAWGCBiIxteo4x5hFjzCRjzCTgh8CHxpiKUF4bblPzMhgzoDd/W7kH3fhcxatqtwdXvdfqMFSUCGVEPx0oNsaUGGPqgReB+W2cvwB4oZOv7TIR4dZZeew4fJK1eyoj+VFKRSWP14fb48Pl1vKl8gsl0ecC+5s8Lg0cO4OIpACXAq924rV3iEihiBQePXo0hLBaN39SLr2THDyzck+X3kepnsjl9o/ka3RErwJCSfTSwrHWaiJXAZ8aYyo6+lpjzJPGmAJjTEF2doubpIQs2WnnhoLBvLP1MEdO1HXpvZTqaVyBhQg6oldBoST6UmBwk8eDgNZmOm/kVNmmo68Nq5tn5uE1hv9bva87Pk6pqBFM8JroVVAoiX4tMEJEhoiIE38yf6P5SSKSDnwJWNLR10ZCflYqc0Zm839r9lHv8XXHRyoVFaoDCb6mwYvPpwsSVAiJ3hjjAe4C3gG2Ay8bY4pEZKGILGxy6jXAu8YYV3uvDec30JZbZuVz9KSbd4oOd9dHKmW5YG3eGKjzaJ1ehdjrxhizFFja7NiiZo//Cvw1lNd2ly+NzOaszBT+tnIPV00caEUISnW76iYlm2q3hxRnzLS0Up0UU3fGNmezCbfMymPtnkq2HTxhdThKdYumtfkat47oVYwneoDrpw4mKcHGs6v2WB2KUt3C1WxEr1TMJ/r0lASunpTL6xsOcLymwepwlIq4pnfE6lp6BXGQ6AG+PiuPugYff1+3v/2Tlerhmo7oXdrcTxEniX7cwHSm5Wfw7Kq9utxMxbym5RpdS68gThI9wNdn5bP3WA2PLS/WZK9iWtMJWJ2MVRBHif7y8f258uwB/Oa9z7nj2UJt4apiVnW9h8xUJ6ClG+UXN4neYbfxhwWT+dm8cXz4+VGu+P0nbNpfZXVYSoWdy+0hp1di49+ViptED4EWxufk8/eF5wBw/aKV2rdexRyX20OflAQS7KI96RUQZ4k+aNLgPvzzO+dy7ogsHlhSxN0vbND1xipmuNxe0hIdpDgd1Oj/14o4TfQAfVKcLL6lgPsuHcXSLYeY94dP2HFY755VPZ+r3kNqooNUp51qnYxVxHGiB3+LhDvnDOf/vjmTk24P1zz+GdsPabJXPZvLHUj0iQ5qdDJWEeeJPmjm0L68dfe5pCba+d7Lm7StserRXG4vqU47KYkOLUkqQBN9o369k3j4mglsO3SCx5YXWx2OUp3i9RlqG7ykJjpIS7RrCwQFaKI/zSXj+nPtlFweX17M5tIqq8NRqsOC6+aDk7G6vFKBJvoz/PSqcWSnJfKfL2+irkFHQ6pnCSb2FKd/MlZvmFKgif4M6ckJ/M9Xzqa4rJrfvve51eEo1SGuwCqb1ES7fzJWV90oNNG36Esjs7lpxlk8+XEJhXsqrA5HqZAFR/RpgVU3OqJXoIm+VT+6fAyDMpL53t836RI11WMEE31qooMUp526Bh8er64ii3ea6FuRlujgka9MZO+xGv7n7R1Wh6NUSIItD1KdDtIS/XvF1uhcU9zTRN+GmUP7ctvsITyzci+fFpdbHY5S7To1orc3bgquK2+UJvp23HfpKIZmp3LfK5s5WadbEaroVn1ajd4OnJqgVfFLE307khLs/Pr6iRw6XsuDb2zTTpcqqgXnk1ISHaQGRvQ6x6Q00Ydg8lkZ3DV3BK+uL9UWCSqqBZuYpSTYSQmM6LUNgnJYHUBPce+FI0iwCb9+73MOHa9j0c1TSU9JsDospU7jcntIddqx2eTUZKyWbuKejuhDJCLcfcEIfvvViRTureC6RZ+xv6LG6rCUOk2wcyVwajJWSzdxL6RELyKXishOESkWkftbOWeOiGwUkSIR+bDJ8XsDx7aKyAsikhSu4K1wzeRBPHv7DMpO1HHNE5+yUbcjVFHEVe9tTPQ6GauC2k30ImIHHgcuA8YCC0RkbLNz+gBPAPOMMeOA6wPHc4HvAAXGmPGAHbgxnN+AFWYO7ctrd55DstPOjU+u5J2iw1aHpBQQHNH7E3ww4etkrAplRD8dKDbGlBhj6oEXgfnNzrkJeM0Ysw/AGFPW5DkHkCwiDiAFONj1sK03PKcXr985m1H9e7PwuXU8/cluq0NSimq3p3G1TUqCjuiVXyiJPhfY3+RxaeBYUyOBDBFZISLrROQWAGPMAeB/gX3AIeC4Mebdlj5ERO4QkUIRKTx69GhHvw9LZKUl8uI3Z3Lx2H489NY2fvPuTqtDUnGupv5Ujd5ht5HosGmNXoWU6KWFY80XkzuAqcAVwCXAT0RkpIhk4B/9DwEGAqkicnNLH2KMedIYU2CMKcjOzg75G7BastPOE1+byrWTc3lsebFuRags5XKfqtGD/8YpvTNWhZLoS4HBTR4P4szySymwzBjjMsaUAx8BE4ELgd3GmKPGmAbgNeCcrocdXew24YGrxtI7OYGH3tSbqpR1qt0e0gI1eoCURLsmehVSol8LjBCRISLixD+Z+kazc5YA54mIQ0RSgBnAdvwlm5kikiIiAlwQOB5z+qQ4+c+LRrKy5BjvFB2xOhwVp1xuT+OySvA3N3PpdoJxr91Eb4zxAHcB7+BP0i8bY4pEZKGILAycsx1YBmwG1gCLjTFbjTGrgVeA9cCWwOc9GZHvJArcNP0sRvZL4+Gl23R3KtXtfD5DTf3ppZvURIeuulGhraM3xiw1xow0xgwzxjwcOLbIGLOoyTmPGGPGGmPGG2MebXL8p8aY0YHjXzfGuMP+XUQJh93GA1eOY39FLU9/qqtwVPcKtiM+rXTjtDe2RVDxS++MDbNzR2Rx0dh+PPZBMUdO1FkdjoojTTcdCUpLdFCjNfq4p4k+An58+RgavD5+tUyXW6ru05jom9ToU5wOarRGH/c00UdAflYqt507hFfXl7JJWySobnJqY/CmNXq7dq9Umugj5a4vDycrLZEH3yzS5ZaqW1Q32V0qSCdjFWiij5heSQncd8koNuyrYsnGmOj6oKJcS6WbVKedBq/B7dHyTTzTRB9BX5k6iAm56fy/t3foqEpFXLDVQfPllaA96eOdJvoIstmEn141lsMn6li04gurw1ExLlijT0s8/YYp0J708U4TfYQV5Gdy1cSB/OmjEkordaMSFTmuFmr0KdqTXqGJvlvcf9loROAbf1lLydFqq8NRMSo4aj+tBUKijuiVJvpukdsnmadvncaxajfzH/uU97drLxwVfi63h+QEO3bbqYazwdKN1ujjmyb6bnLO8CzevPtczuqbwu3PFPLovz7H59Nllyp8qpu1KAZ/CwT/czqij2ea6LvRoIwUXv3WOVw7JZdH/7WLO55dx4m6BqvDUjGi6TaCQWm6naBCE323S0qw8+vrJ/LgVWNZvrOMqx/7lOKyk1aHpWJATb3ntDX00GQyVtsgxDVN9BYQEb4xewjP//sMTtQ1MP+xT1m29RD1Hh+19V5O1jVQVVNPebWbIyfqOFBVy7HqmG36qcLEv+nI6Ym+cXmllm7imqP9U1SkzBzalzfvPpeFz61n4XPr2zzXJrDsnvMZ2a9XN0WnehqX20vfNOdpx5IT7IigHSzjnCZ6iw1IT+alO2by0tr9VLs92G2CwyZNvvp/6XpgyVb+XrifH18x1uKIVbRy1Xs4KzHltGM2m5CSoD3p450m+iiQlGDn1nPy2zxn+c4yXt9wkB9cOhqHXStu6kwut4c055n/pLWxmdKM0UNcN2UQ5dVuPt5VbnUoKkq5WlheCf5Er5Ox8U0TfQ8xd3QOGSkJvLK+1OpQVBQyxuCqP3N5JfjX0utkbHzTRN9DOB025k0cyHvbjnC8Rtfeq9PVNngxhtZH9Jro45om+h7kuqmDqPf4eGuL9rdXp6tuYb/YoFSnXbcTjHOa6HuQCbnpjMhJ49V1Wr5Rp2vcRtDZQulGR/RxTxN9DyIiXDd1EOv3VWkXTHUaVxsj+jSnQ7tXxjlN9D3MNZNzsQm8tv6A1aGoKBJM9M3vjAV/GwTtXhnfNNH3MP16J3HuiGxe33BAu1+qRi1tIxiUlugf0esm9fFLE30PdN2UXA5U1bKq5JjVoagoUd1Wjd7pwGegrsHX3WGpKBFSoheRS0Vkp4gUi8j9rZwzR0Q2ikiRiHzY5HgfEXlFRHaIyHYRmRWu4OPVJeP60yvRoWvqVaOatlbdJGpP+njXbqIXETvwOHAZMBZYICJjm53TB3gCmGeMGQdc3+Tp3wHLjDGjgYnA9vCEHr+SEuxccfYAlm09rKspFNDe8krtSR/vQhnRTweKjTElxph64EVgfrNzbgJeM8bsAzDGlAGISG/gfOCpwPF6Y0xVmGKPa9dNHURNvZe3tx62OhQVBdpaXpmqG4THvVASfS6wv8nj0sCxpkYCGSKyQkTWicgtgeNDgaPAX0Rkg4gsFpHUlj5ERO4QkUIRKTx69GgHv434U5CXQV7fFF1TrwD/aD3RYWux4V1ws3BdYhm/Qkn00sKx5tP3DmAqcAVwCfATERkZOD4F+KMxZjLgAlqs8RtjnjTGFBhjCrKzs0ONP26JCNdOHsTKkmOUVtZYHY6yWEubjgQFyzla5otfoST6UmBwk8eDgOb34Jfir8O7jDHlwEf46/GlQKkxZnXgvFfwJ34VBtdO8f9i9Y8NuqY+3vn3i20t0ftLN9oGIX6FkujXAiNEZIiIOIEbgTeanbMEOE9EHCKSAswAthtjDgP7RWRU4LwLgG1hij3uDc5MYfqQTF5df0DXSMc5V72XlBbq83BqMlZX3cSvdhO9McYD3AW8g3/FzMvGmCIRWSgiCwPnbAeWAZuBNcBiY8zWwFvcDTwvIpuBScAvwv5dxLGvTBnE7nIX6/dVWR2KspArhNKNbicYv0LaYcoYsxRY2uzYomaPHwEeaeG1G4GCzoeo2nLZhP488MZWXl1fytS8DKvDURZxuT30SXG2+FxwpK+bj8QvvTO2h+uVlMCl4/rz5saDHKt2Wx2Oski1u+VNRwD/ahyb6GRsHNNEHwPu/PJwahu8/M+yHVaHoixSU+9trMU3JyKkaE/6uKaJPgaM7NeL288bwsuFpRTuqbA6HGWB6jZW3YC/Tq+TsfFLE32M+M7cEQxMT+LHr2+lwavNq+KJMSawvLLl0g34E722QIhfmuhjRGqig5/OG8fOIyf566d7rA5HdSO3x4evlf1ig1Kddm2BEMc00ceQi8f2Y+7oHH77r885dLzW6nBUN6luY9ORoBSnbicYzzTRxxAR4WfzxuH1GX7+lt6XFi8atxFsZTIW/KN9XV4ZWcYYPthxJCp/oGqijzGDM1O4e+5wlm45zIqdZVaHo7rBqRbFbdXo7Vqjj7BPi49x218Lufmp1VTV1Fsdzmk00cegb54/lKHZqTywpIi6Bh3Fxbrgssn2Vt1E40gzlqwsKcduE4oOnODGJ1dRdrLO6pAaaaKPQYkOO//f/PHsq6jhiRVfWB2OirC2Nh0J0snYyFtVUsHZg9J5+hvT2FdRww2LVrK/Ijo6y2qij1HnDM9i/qSBLFrxBbvLXVaHoyIolBp9itNBbYMXr24oHxE19R42l1YxY0hfzh2RxbO3z6DCVc/1i1ZSXHbS6vA00ceyH18xhkSHjQeWbNXuljGsJri7VBs1+uCKHK3TR8b6vVU0eA0zh2YCMDUvg5f+YxYen+GGP61i64HjlsaniT6G5fRK4r8uGcXHu8p5a/Mhq8NRERLS8krtSR9Rq3cfw24TCvIzG4+NGdCbvy+cRXKCnQVPrmJ1yTHL4tNEH+NunpnHhNx0frJkK3u0hBOTgqWblLaWV2pP+ohaVXKM8bnpZ/ywHZKVyivfmkVO70RueXoNy3dYsxJOE32Ms9uEx26ajAC3P7OW47UNVoekwqy63oPTbsPpaP2f86me9DqiD7faei+b9h9n5pDMFp8fkJ7My/8xixH90rjj2UJ2Hu7+mr0m+jiQ1zeVRTdPZV9FDXf933o82gsnptS4vW3W58G/6gZ0g/BI2LCvknqvj5lD+7Z6Tt+0RP522wx/q5I3un/OTBN9nJgxtC8PXz2Bj3eV612zMaat/WKDdIPwyFm1uwKbQEF+2xv/ZKY6+a+LR7GqpKLb58w00ceRG6YN5o7zh/LMyr08u3KP1eGoMKl2e9pcWgmnVuRoG4TwC9bneyUltHvugulnMW5gbx7+5/Zu/aGriT7O/ODS0Vw4JocH39zGx7uOWh2OCoOa+vZLN8GJWh3Rh1ddg5eN+6uY0Up9vjm7TXho/jgOn6jjseXFEY7uFE30ccZuEx69cTIjctK48/n1FJdVWx2S6qL2Nh0BLd1EyoZ9VdR72q7PNzc1L5Prpgxi8ccllBztnn9/mujjUFqig8W3FpDosHH7M2updEVXAybVMa4QSjfBDcJ1HX14rd59DBFOWz8fivsvG02Sw86Db27rlolZTfRxalBGCn/6egGHjtex8Ll11Ht0JU5PFcpkbEJg+aWO6MNrVckxxg3sTXpy+/X5prJ7JXLvRSP56POjvLftSISiO0UTfRybmpfBr647m9W7K3jorSKrw1Gd5Kr3ktZOjR78v8np8srwqWvwsmGfv79NZ9wyK49R/Xrx0FvbIt5lVhN9nLt6ci7/cf5Qnlu1jyUbD1gdjuqgU/vFtj2iB3/5Rm+YCp9N+6twd7A+35TDbuPBeeMorazljxHuMquJXvFfl4xiWn4GP3xtS1R02lOhc3t8eHwmpESf6nRoC4QwWr27AhGY3sH6fFOzhvXlqokD+eOHX7DvWORaGmuiVyTYbfxhwRSSE+zc+fx67XDYgzRuOuJsv3Tj32VKR/ThsqrkGGP69yY9pWP1+eZ+dPloHDbh5/+M3I2MISV6EblURHaKSLGI3N/KOXNEZKOIFInIh82es4vIBhF5KxxBq/Drn57E726czK6yav77H9rWuKdwhbDpSFCq1ujDxu3xsn5fJTOGdn40HzQgPZm7547gvW1HWB6h7T/bTfQiYgceBy4DxgILRGRss3P6AE8A84wx44Drm73Nd4Ht4QhYRc65I7L47gUjeG39AV5au9/qcFQIQtldKijVqdsJhsvm0uPUNXS+Pt/c7ecOYWhWKg+9uQ23J/y/dYUyop8OFBtjSowx9cCLwPxm59wEvGaM2QdgjGn8sSQig4ArgMXhCVlF0t1zR3DeiCweeKOIooPWbpag2teREX1Kom4nGC7B3vJdqc835XTY+PnV4/m32fnYRcLynk2FkuhzgabDu9LAsaZGAhkiskJE1onILU2eexS4D2hzobaI3CEihSJSePSo3ppvFbtN+O1XJ5GRksC3n1/PiTptaxzNgr1rQllemerU0k24rCqpYHT/XmSkOsP2nrOHZ3HLrHwc9vBPnYbyji39eGlewHUAU/GP3C8BfiIiI0XkSqDMGLOuvQ8xxjxpjCkwxhRkZ2eHEJaKlKy0RB67aQr7K2v5wSubtV4fxTpao9fllV1X7/Gxbm9l2Mo23SGURF8KDG7yeBBwsIVzlhljXMaYcuAjYCIwG5gnInvwl3zmishzXY5aRdy0/Ex+cOko3t56mL98usfqcFQrqkPYGDwo1Wmn3uvTu6C7aMuBKmobvI37w/YEoST6tcAIERkiIk7gRuCNZucsAc4TEYeIpAAzgO3GmB8aYwYZY/IDr/vAGHNzGONXEfTN84Zy4Zh+/GLpdtbvq7Q6HNWCmg7V6HWD8HBYVVIBwPRO3hFrhXYTvTHGA9wFvIN/5czLxpgiEVkoIgsD52wHlgGbgTXAYmPM1siFrbqDiPDr6ycyoE8Sdz2/ngptfhZ1gjX69toUw6k6vvak75pVJccY1a8XmWGsz0daSFV/Y8xSY8xIY8wwY8zDgWOLjDGLmpzziDFmrDFmvDHm0RbeY4Ux5sqwRa66RXpKAn/82lTKXfV898UNeH1ar48m1W4PDpvgDGECL9iTvkaXWHZag9dfnw/H+vnupHfGqnaNz03nZ/PG8fGucv7wwS6rw1FNBPvcSAhL8tICpRttg9B5Ww4cp6be2+lGZlbRRK9CcuO0wVw7JZffvb+LDz/X5a/RwuX2Nibw9mhP+q5bHajP64hexSQR4eGrJzCqXy/ueXEDB6tqrQ5JERzRt1+fh1MTtjqi77xVJccYnpNGVlqi1aF0iCZ6FbJkp50nvjaFBq/hzufX6zK9KOCq9zTW3tuTqqtuumR/RQ1r91SEvD9sNNFErzpkaHYav/rK2WzcX8Uvlmr7Iqu53J6QSzfBDpfaBqHjjlW7ufXpNThswr/NHmJ1OB2miV512OUTBnD7uUP462d7eHNT83vnVHdyub0hl25SdIPwTnG5Pdz217UcqKrlqW9MY3hOmtUhdZgmetUp9182moK8DO5/dTPFZd2zk706U3UIG4MHpSToOvqOqvf4WPjcOrYcOM5jN01hWpiamHU3TfSqUxLsNh67aQpJCXa+9dw6rftapKY+tG0EAWw2CWwnqP+tQuHzGe57ZRMf7yrnl9dO4KKx/awOqdM00atO65+exO8X+Dcr+dWynVaHE5f8pZvQEj3o5iOhMsbw8NLt/GPjQb5/ySi+Ou0sq0PqEk30qktmD8/i32bn89fP9vDZF+VWhxNVCvdUUBvBMkm9x0e91xfSNoJBqU7tSR+KJz8q4alPdvONc/K5c84wq8PpMk30qsvuu2Q0Q7JSue+VzbpGO6C0sobr/7SSv3y2O2Kf0ZEWxUEpToeW2drxyrpSfvn2Dq44ewAPXDk2pLuOo50metVlyU47/3v92RysquXhf+qSS/B3ODTmVKfDSAiWYEJdXhk8V38Yt275jjJ+8OpmZg/vy29umIjN1vOTPGiiV2EyNS+Tb543lBfW7NMWCZzaam793sqINYILlmA6NKJPtGsLhFbsr6jhOy9sYHT/Xiy6eSqJjtBLYtFOE70Km3svGsmInDR+8MpmjtfG9xaEq3dXkJxgp9rtYfuhExH5jODIPCXEdfTg36BER/Rn8nh93PvSRgAW3TyVXkkJ1gYUZproVdgkJdj59Q0TOVrt5qE3t1kdjmUOHa9lX0UNN8/0r9RYszsy5ZuaTpRuUhPtup1gC55Y8QWFeyv5+dXjGZyZYnU4YaeJXoXV2YP6cOecYby6vpR/bTtidTiWCHY4nD8pl9w+yazdE5lE7+rANoJBKbpB+BnW7a3kd+/v4upJA7l6cq7V4USEJnoVdnfPHcHo/r344etbqOzirlRPf7I7YiPiSFm9+xi9khyMGdCb6UMyWbunIiIbrFe7Q99dKig10Y7L7dEN3wNO1jVwz0sbGJCexENXj7c6nIjRRK/Czumw8esbJlLpquenbxR1+n1e31DKQ29t49fv9qybsVaXVDA9PxO7TZiWn0l5dT27y11h/5zOLK9MTXTgM+DWzqMA/HRJEQcqa3n0q5PoHWN1+aY00auIGDcwne9cMII3Nh3k7S2HOvz63eUu/vv1rSTYhcK9lRyv6RmTu2Un6igpdzVuTDF9SAYQmTp9Z5ZXBss82tgMlmw8wGsbDnD33BEU9NAeNqHSRK8i5ltzhjEhN50fvr6FXUdOhvy6eo+P77ywAYfdxm+/Ogmvz/DRrp6xZHN1IKEHt5oblp1GZqqTNRGo07vcHuw2IdER+j/j1MYOlvE9IVtaWcN//2MrU/MyuHvucKvDiThN9CpiEuw2/rBgMgl2G19bvDrk8sWvlu1gy4HjPPKVs7ls/AAyU518sKMswtGGx+rdx0hLdDBuYG/AvzPXtPyMiEzIutxeUpz2Dt252diTPo4nZINLKY2BR786CUcIG6v3dLH/HSpL5Wel8vy/z8DjM9z051Xsr6hp8/zlO8pY/MlubpmVx8Xj+mO3CXNGZrN8Z1nEbjwKp9UlFUzNyzgteUzLz2R/RS2Hj9eF9bM6sulIUIruMsUfV3zB2j2V/PzqcTG5lLIlmuhVxI3s14vnbp9BTb2XmxavanW/2SMn6vje3zcxun8vfnT5mMbjc8fkUFXTwIZ9ld0Vcqccq3azq6z6jI2jpwe2ngt3+cbVgRbFQWmBFTrVcVq62bCvkkff38X8SQO5ZvIgq8PpNproVbcYO7A3f7ttOlWuBr62eDVlJ04f3Xp9hntf2khtvZfHbppMUsKpJYPnjcjGYRPej/LyzZpm9fmgsQN6k+q0szbME7LVbm+HOlcCjfvLxmtP+t+/v4u+qU5+HsNLKVuiiV51m4mD+/DX26Zx5EQdNy1eTXm1u/G5RR9+wWdfHONn88YxPKfXaa9LT05gWn4my6M80QfbHpw9KP204w67jSl54a/Tu9wdH9EHV93EYxuEareHT4uPMW/iwJheStkSTfSqW03Ny+SpW6exv6KGmxevpqqmnnV7K/jNe59z1cSBXF/Q8q/TF4zJYcfhk5RWtl3jt9KqkmNMzcsgoYXJvWn5mew8cjKsy0Q7legDpZt4bGy2YmcZ9V4fF4/rb3Uo3S6kRC8il4rIThEpFpH7WzlnjohsFJEiEfkwcGywiCwXke2B498NZ/CqZ5o1rC9/vqWAkqMuvv7UGr7zwkYG9kni4WvGt7qC5MujcwCidlRfVVPPziMnmTGk5fXY0/IzMQYK94ZvVO+q93S4dNO4vDIOJ2PfLTpC31QnU/MyrA6l27Wb6EXEDjwOXAaMBRaIyNhm5/QBngDmGWPGAdcHnvIA3zPGjAFmAt9u/loVn84fmc0fb57C9kMnOHKijj8smNLmr9NDs1LJ75sStXX6Nbv9/ednDO3b4vOTz+pDgl3COiHb0W0EARIdNuw2ibsbpuo9PpbvKOPCMf2wx0iP+Y4I5f+S6UCxMaYEQEReBOYDTdsT3gS8ZozZB2CMKQt8PQQcCvz9pIhsB3KbvVbFqQvG9OP5f59BTYOXSYP7tHmuiDB3dD+eW72XmnpP46RitFi9u4JEh42Jg9NbfD4pwc6E3PSwTsh2ZnmliH+D8Hi7YWplyTFOuj1cPK7nbvDdFaGUbnKB/U0elwaONTUSyBCRFSKyTkRuaf4mIpIPTAZWt/QhInKHiBSKSOHRoz3jLkjVdTOG9uXLo3JCOveCMTnUe3x8VnwswlF13Ordx5h8Vp82N6uYNiSTLQeOU9fQ9STr8fpwe3wdHtGDf0I23tbRv1t0mBSnndnDs6wOxRKhJPqWfs9pfueKA5gKXAFcAvxEREY2voFIGvAqcI8xpsVdGIwxTxpjCowxBdnZ2SEFr+LLtPxM0hIdUVe+OVHXwLaDJ85YVtnc9PxMGryGDfuquvyZwRF5Sgdr9BDsYBk/I3qfz/DetiPMGZV92rLdeBJKoi8FBjd5PAg42MI5y4wxLmNMOfARMBFARBLwJ/nnjTGvdT1kFa+cDhvnjcjigx1HoqrNbuGeCnyGM26Uaq4gLxMRwrLMsroTDc2CUhPjqyf9xtIqyk66uXhs/K22CQol0a8FRojIEBFxAjcCbzQ7Zwlwnog4RCQFmAFsF/8SiqeA7caY34QzcBWf5o7O4cgJN0UHI7M9X2esLqnAabcx5ay2V3OkpyQwql+vsCT6mk60KA7y1+jjJ9G/W3QEh01CLhHGonYTvTHGA9wFvANsB142xhSJyEIRWRg4ZzuwDNgMrAEWG2O2ArOBrwNzA0svN4rI5RH6XlQcmDMqB5HoWma5ancFEwenh1QWmJafyfq9lXi8XesHX92Y6DteikhLdMRV6ebdbYeZObQv6SnxdZNUUyGtozfGLDXGjDTGDDPGPBw4tsgYs6jJOY8YY8YaY8YbYx4NHPvEGCPGmLONMZMCf5ZG5DtRcSG7VyITB/WJmjp9tdvD1gPH263PB00bkomr3su2Lm4YHkzUHdlGMCgljiZji8tOUnLUxSVxutomSO+MVT3OBaNz2FRaxdGT7vZPjrB1eyvx+ky79fmg6YENLrq6EUmwxt6pVTeJjrhpavZOkX/f4gvHaqJXqkf58ugcjPHf0m611SXHcNgk5Lst+6cncVZmSpfr9MEae6cmY532uBnRv7vtCBMHpTMgPdnqUCyliV71OOMG9qZf78So2Ixk9e4KJgxK79ANXNPyM1m7p7JLK4eCiT6lEzX6lEQHNfVefD2gv39XHD5ex6b9VXHZ26Y5TfSqxwneJfvxrnLqLdzkurbey+bSqpDr80HTh2RQ4arni6PVnf7sYOmlMyP6YE/6mjDcuBXN3tt2GCDu6/OgiV71UBeMzqHa7YnIFn2hWr+vkgZv6PX5oGmNdfrOb6RSU+9BBJI7cQNQvPSkf3fbEYZmpTIsO83qUCyniV71SLOHZ5HosPH+duvKN6tLjmETKOhgN8QhWalkpTm79EOq2u0h1eno0H6xQcElma4YblV8vKaBlV8c4+Jx/Tt1jWJNdHWGUipEyU47s4b15YMdR3jgqu5viLq73MU7RUcYn5tOrw5uYuHfMDyz1ZU3bo+XE7UeXG4PHp8Pj8/g8Rq8PoPH5/+691hNp9bQw6klmbF809TynWV4fCZum5g1p4le9VgXjM7hJ0uK+MeGA2SkOls8Jy3RzpSzMsIyqjPGsPKLYzz1yW4+2FmGwyb84poJnXqvafmZvL31MLc8vQaX28Px2gZO1DZwoq6BuobQ5h3G5/bu1Gc39qSP4UT/7rbDZPdKZNKgPlaHEhU00asea+6Yfjz45jbueWljm+ddOzmXX143oc3Okm2pa/DyxqaDPP3JbnYcPknfVCd3zx3BzTPPIqdXUqfe86Kx/Xi5cD8VLjfpyQnk9Eqjd1IC6SkJ9E5ykJ6cQGqiA4fdhsMm2G3S5Ku/p/yw7NROfXawEVqs9rupa/CyYudRrp6ciy0Oe8+3RBO96rFy+yTz3r3nU9nG9nwffn6U37+/i9LKWv709amtjvxbUl7t5tmVe3l+9V7Kq+sZ3b8Xv7rubOZNGtjlLoiDM1NYds/5XXqPzkprHNFbU6N/a/NB0pMTOG9EZLrUflpcTk29l0t0WWUjTfSqRxvazoqKqXkZDMtO5fuvbOaaJz7lqW9Ma3cVRoPXxzOf7eF3/9pFdb2HC0bncNvsIcwa1jcmJvZSAoneipumHl9ezCPv7ATgP740lO9fPApHC3vsdsW7RUfolehgViu7fcUjTfQq5s2flMugjGTu+Ns6rn3iMxbdPJVZw1pOAp8Wl/PgG0XsKqvmSyOz+cmVYxie06ubI46stMBk7Mm67kv0xhh++97n/P6DYuZPGkhaooM/fVjChn1VPLZgMjm9O1cCa87rM/xr+xHmjM7B6dBFhUGa6FVcmJqXyet3zua2Z9Zyy9OrefiaCdxQcGqbhQNVtTz8z20s3XKYwZnJ/PmWAi4ckxMTI/jmeic76JvqZPuhk93yecYYfvn2Dp78qISvFgzmF9dOwG7zrzz64WtbuPz3n/D7BZM4Z1j7uz/VNXgp3FPJyboG3B4fdQ3e074ePlHHMVe93iTVjCZ6FTfO6pvCq986h28/v577XtnMnnIXd88dweKPS3h8RTEA37toJN88f2hM70QkIhTkZ3TLzWY+n+HBN4v428q93DIrjwevGtc4QXr15FzGDezNt55fz82LV/OfF43kzjnDz5hAbfD6+KS4nDc3HuTdbUcaWzS3xGET8vqmMCeOe8+3RBO9iivpyQn85d+m8cCSIp5Y8QV/W7mXareHyyf058dXjCW3T3w0v5qWn8k7RUc4cqKOfmEqmzTn9Rl+9NoWXirczx3nD+WHl40+4zekEf16seTbs/nR61v433c/p3BvJb+9YRLpyQms3l3Bm5sP8vaWQ1TWNNA7ycEVEwZw2YT+9OudRFKCnUSHrfFrosMW9np/rNBEr+JOgt3GL64Zz/CcNJZtPcQ9F46Mu02jg20Y1u6p4MqzB4b9/T1eH//19038Y+NBvjN3OPdeNLLVMlhqooNHvzqJafmZPPTmNi773ccYDEdOuElOsHPR2H7MmziQ80dma929kzTRq7gkItx+7hBuP3eI1aFYYuzA3iQn2CncUxn2RF/v8XHPSxtYuuUw379kFN/+8vB2XyMi3Dwzj7MHpfPgG0X0TUtk3sSBXDAmp0OdQVXL9AoqFYcS7DYmn9WnUxugGGPYX1FLaWUNB4/XcbCqlkPHazlQ5f/7wapaauq9/OTKsR3+QXr2oD68dufsDsek2qaJXqk4NS0/kz98sIsTdQ307kC/nhfW7OdHr2857VhWmpOBfZIZnp3GeSOyOGdYFhfF+a5O0UQTvVJxalp+Jj4DG/ZV8aWRod+lunTLIfL6pvDLayYwsE8y/dOTYnqVUizQmQ2l4tTks/pgtwlrO1C+OVnXwOrdx7h0XH/OGZ5FflaqJvkeQBO9UnEqNdHBuIG9O7Se/pNd5TR4DXNH6zr1nkQTvVJxrCAvk437q3B7Qmtw9v6OMnonOULeDF1FB030SsWx6UMycHt8bD1wot1zfT7D8h1lzBmVozcm9TD6X0upODY1z3/jVGEI5ZtNpVUcc9VzwRgt2/Q0muiVimPZvRIZmpUaUp3+gx1l2IQOrdBR0SGkRC8il4rIThEpFpH7WzlnjohsFJEiEfmwI69VSlmnID+Dwr2V+HymzfPe315GQV4mfVJC37xFRYd2E72I2IHHgcuAscACERnb7Jw+wBPAPGPMOOD6UF+rlLLWtPxMqmoaKD5a3eo5h47Xsu3QCeZq2aZHCmVEPx0oNsaUGGPqgReB+c3OuQl4zRizD8AYU9aB1yqlLNS0wVlrPtjh/yd9gS6r7JFCSfS5wP4mj0sDx5oaCWSIyAoRWScit3TgtQCIyB0iUigihUePHg0teqVUl+X1TSErLZHCPZWtnvPB9jIGZyYzPKftbRhVdAol0bfUW7R5Mc8BTAWuAC4BfiIiI0N8rf+gMU8aYwqMMQXZ2TrZo1R3ERGmD8lotcFZbb2XT4rLuWB0v5jccSsehJLoS4HBTR4PAg62cM4yY4zLGFMOfARMDPG1SimLFeRlciDQebK5lSXluD0+vRu2Bwsl0a8FRojIEBFxAjcCbzQ7Zwlwnog4RCQFmAFsD/G1SimLTR/Sep3+/e1lpDjtzBia2d1hqTBpN9EbYzzAXcA7+JP3y8aYIhFZKCILA+dsB5YBm4E1wGJjzNbWXhuZb0Up1Vmj+/ci1Wk/o05vjOGDHWWcNyKLRIc2L+upQmpTbIxZCixtdmxRs8ePAI+E8lqlVHRx2G1MyTtzw/Dth05y6Hgd91440qLIVDjonbFKKcC/zHLnkZMcr21oPPbBjiMAzBmtCyR6Mk30SinAf4esMbB+76nyzfs7ypg4KJ2cXkkWRqa6ShO9UgqAyYMzcNiENYHyTXm1m437q5g7WrcE7Ok00SulAEh22hmfm97YyXLFzqMYg3arjAGa6JVSjaYPyWTT/uPUNXj5YMcR+vVOZNzA3laHpbpIE71SqlFBXgb1Xh/r91by0eflzB2do3fDxgBN9EqpRgWBBmdPrPiCareHC7Q+HxM00SulGmWmOhmek8YnxeUkOmzMHp5ldUgqDDTRK6VOMy3fv/H3OcP6kuzUu2FjgSZ6pdRpgv3p547Rsk2s0ESvlDrNRWP7cdvsIcybONDqUFSYhNTrRikVP3olJfDAVbrjZyzREb1SSsU4TfRKKRXjNNErpVSM00SvlFIxThO9UkrFOE30SikV4zTRK6VUjNNEr5RSMU6MMVbHcAYROQrs7eTLs4DyMIYTThpb52hsnaOxdU5PjS3PGNPi5r5Rmei7QkQKjTEFVsfREo2tczS2ztHYOicWY9PSjVJKxThN9EopFeNiMdE/aXUAbdDYOkdj6xyNrXNiLraYq9ErpZQ6XSyO6JVSSjWhiV4ppWJczCR6EblURHaKSLGI3G91PE2JyB4R2SIiG0WkMArieVpEykRka5NjmSLynojsCnzNiKLYHhSRA4Hrt1FELrcgrsEislxEtotIkYh8N3Dc8uvWRmzRcN2SRGSNiGwKxPazwPFouG6txWb5dWsSo11ENojIW4HHnbpuMVGjFxE78DlwEVAKrAUWGGO2WRpYgIjsAQqMMVFxE4aInA9UA38zxowPHPsVUGGM+X+BH5QZxpgfRElsDwLVxpj/7e54msQ1ABhgjFkvIr2AdcDVwDew+Lq1EdsNWH/dBEg1xlSLSALwCfBd4Fqsv26txXYpFl+3IBH5T6AA6G2MubKz/05jZUQ/HSg2xpQYY+qBF4H5FscUtYwxHwEVzQ7PB54J/P0Z/Imi27USm+WMMYeMMesDfz8JbAdyiYLr1kZsljN+1YGHCYE/hui4bq3FFhVEZBBwBbC4yeFOXbdYSfS5wP4mj0uJkv/RAwzwroisE5E7rA6mFf2MMYfAnziAHIvjae4uEdkcKO1YUlYKEpF8YDKwmii7bs1igyi4boHyw0agDHjPGBM1162V2CAKrhvwKHAf4GtyrFPXLVYSvbRwLGp+MgOzjTFTgMuAbwfKEyp0fwSGAZOAQ8CvrQpERNKAV4F7jDEnrIqjJS3EFhXXzRjjNcZMAgYB00VkvBVxtKSV2Cy/biJyJVBmjFkXjveLlURfCgxu8ngQcNCiWM5gjDkY+FoGvI6/1BRtjgRqvcGab5nF8TQyxhwJ/IP0AX/GousXqOO+CjxvjHktcDgqrltLsUXLdQsyxlQBK/DXwKPiugU1jS1KrttsYF5gfu9FYK6IPEcnr1usJPq1wAgRGSIiTuBG4A2LYwJARFIDE2SISCpwMbC17VdZ4g3g1sDfbwWWWBjLaYL/YwdcgwXXLzBx9xSw3RjzmyZPWX7dWostSq5btoj0Cfw9GbgQ2EF0XLcWY4uG62aM+aExZpAxJh9/PvvAGHMznb1uxpiY+ANcjn/lzRfAj62Op0lcQ4FNgT9F0RAb8AL+X0kb8P82dDvQF3gf2BX4mhlFsT0LbAE2B/5HH2BBXOfiLwduBjYG/lweDdetjdii4bqdDWwIxLAVeCBwPBquW2uxWX7dmsU5B3irK9ctJpZXKqWUal2slG6UUkq1QhO9UkrFOE30SikV4zTRK6VUjNNEr5RSMU4TvVJKxThN9EopFeP+f6WBZ5LFLHopAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(rn.losses)\n",
    "plt.plot(rn.val_losses)\n",
    "plt.show() #뭐지 왜 하나만 뜨지. 아무튼 그래프가 좀 들쭉날쭉하지만 손실이 잘 감소되고 있음을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6432"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "# 정확도 평가\n",
    "rn.score(x_val_onehot, y_val) # 약 64%다. 영화의 리뷰가 긍정인지 부정인지 맞출 확률이 64%라는 뜻. 텐서플로를 이용하면 더 정확도를 높일 수 있을거 같다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터셋으로 문자열을 저장할거란 생각은 하지 않았다. 역시 그랬다. 사전의 인덱스값들을 저장해놓고 사전 파일을 따로 만들었구나. \n",
    "# 이걸 원-핫 인코딩으로 만드는건 예외였다. 생각해보니 행렬 연산 하는걸 생각하면 원-핫 인코딩으로 행렬 연산이 요구하는 입력값에 맞추는게 맞구나. 그래야하네. 아하. \n",
    "# 선형대수학 복습해야겠다. 뭔 계산할 때마다 행렬 연산으로 머리 잡고 있냐. 흑흑."
   ]
  }
 ]
}