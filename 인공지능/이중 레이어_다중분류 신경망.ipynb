{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Import "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 의류 데이터 분류하는 모델 만들어보기 \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf # 텐서플로우 import \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "tf.__version__ # 버전 확인"
   ]
  },
  {
   "source": [
    "# 데이터 불러오기 & 전처리"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "(x_train_all, y_train_all), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data() # 데이터 불러오기. 튜플로 묶어서 반환"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 세트의 크기 확인\n",
    "print(x_train_all.shape, y_train_all.shape) # x_train_all : 28*28 크기를 가진 60000개의 데이터가 있음\n",
    "# y_train_all : 60000개의 데이터를 가진 1차원 배열. 답이 0~9의 숫자로 들어있음\n",
    "class_names = ['티셔츠/윗도리', '바지', '스웨터', '드레스', '코트', '샌들', '셔츠', '스니커즈', '가방', '앵클부츠'] # 0~9의 답을 이렇게 표시."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2020-12-31T20:09:56.161864</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 251.565 248.518125 \nL 251.565 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \nL 244.365 7.2 \nL 26.925 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#pee14d7c15e)\">\n    <image height=\"218\" id=\"imagef563652962\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\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\" y=\"-6.64\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m01713edaa7\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#m01713edaa7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(27.626607 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#m01713edaa7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <g transform=\"translate(66.455179 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#m01713edaa7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 10 -->\n      <g transform=\"translate(102.1025 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#m01713edaa7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 15 -->\n      <g transform=\"translate(140.931071 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#m01713edaa7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 20 -->\n      <g transform=\"translate(179.759643 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#m01713edaa7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 25 -->\n      <g transform=\"translate(218.588214 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"md2040c125c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#md2040c125c\" y=\"11.082857\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 14.882076)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#md2040c125c\" y=\"49.911429\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 53.710647)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#md2040c125c\" y=\"88.74\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 92.539219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#md2040c125c\" y=\"127.568571\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 131.36779)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#md2040c125c\" y=\"166.397143\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 170.196362)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#md2040c125c\" y=\"205.225714\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 209.024933)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 224.64 \nL 26.925 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 244.365 224.64 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 7.2 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pee14d7c15e\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# 샘플 이미지 확인\n",
    "plt.imshow(x_train_all[0], cmap='gray') # 넘파이 배열을 입력받아 이미지로 표현. cmap(colormap, 색을 표현함. 기본 설정은 viridis(짙은 녹색~밝은 노란색 사이로 표현)이며 따로 값을 줄 수 있음. 이 경우에는 'gray'로 설정)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[9 0 0 3 0 2 7 2 5 5]\n앵클부츠\n"
     ]
    }
   ],
   "source": [
    "print(y_train_all[:10]) # 답지 보기. 숫자로 나와있다.\n",
    "\n",
    "print(class_names[y_train_all[0]]) # 한글로 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# 타깃 분포 확인(데이터가 균등히 분포 되었는지 확인. 정수값의 등장 횟수 카운트)\n",
    "np.bincount(y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 세트와 검증 세트로 분류. train_test_split() 사용\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, stratify = y_train_all, test_size = 0.2, random_state = 42) # random_state는 안해도 되는데 예제랑 같다는 걸 보여주기 위해 사용한 것. 20%(test_size = 0.2)를 검증 세트로 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200])"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "# 같은 비율로 나눠졌는지 체크\n",
    "np.bincount(y_train) # 4800개씩 있음\n",
    "np.bincount(y_val) # 1200개씩 있음 \n",
    "\n",
    "# 데이터 불러오기 -> 분류 -> 가공하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터 정규화. 0~1사이 값으로 나타내기 위해 255로 나눠줌 \n",
    "x_train = x_train / 255\n",
    "x_val = x_val / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28*28를 784(28*28하면 나오는거)로 변경. 왜냐하면 내가 설계한 모델은 1차원 배열을 요구하기 때문.\n",
    "#한 줄로 쫙 이어붙혔다고 보면 된다.\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "x_val = x_val.reshape(-1,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(48000, 784) (12000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_val.shape) # 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# 타깃 데이터를 준비하고 다중 분류 신경망 훈련\n",
    "# 10개의 클래스(상의 등)가 있으니 이에 맞춰 출력값을 가공해야함 -> [1,0,0,0,0...], [0,0,...0,1]와 같이 정답으로 처리한 클래스의 인덱스에 해당하는 값은 1, 나머지는 0인 벡터로 정답 데이터를 가공 -> 원-핫 인코딩(one-hot encoding). \n",
    "# 세상에는 참 똑똑한 사람들이 많다\n",
    "# to_categorical()로 원-핫 인코딩을 수행할 수 있다. \n",
    "tf.keras.utils.to_categorical([0,1,3]) # 테스트\n",
    "# [1., 0., 0., 0.],\n",
    "# [0., 1., 0., 0.],\n",
    "# [0., 0., 0., 1.]] 이렇게 나온다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 데이터들을 원-핫 인코딩 처리\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_val_encoded = tf.keras.utils.to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(48000, 10) (12000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_encoded.shape, y_val_encoded.shape) # 크기 확인. (48000, )의 1차원에서 (48000, 10)의 2차원 배열로 바뀜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0], y_train_encoded[0]) # 잘 나오는지 체크. \n",
    "# 6 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]로 나오는데 encoded값을 보면 인덱스가 6에 해당하는 배열에 해당하는 원소가 1이고 나머지는 0인 것을 확인할 수 있다. "
   ]
  },
  {
   "source": [
    "# 모델 클래스"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단일 레이어\n",
    "class SingleLayer:\n",
    "    def __init__(self, learning_rate = 0.1, l1=0, l2=0):\n",
    "        self.w = None # 가중치\n",
    "        self.b = None # 절편\n",
    "        self.losses = [] # 훈련 데이터에 대한 손실\n",
    "        self.val_losses = [] # 검증 데이터에 대한 손실\n",
    "        self.w_history = [] # 가중치 기록\n",
    "        self.lr = learning_rate # 학습률(내가 따로 지정하는거)\n",
    "        self.l1 = l1 # L1손실 하이퍼 파라미터\n",
    "        self.l2 = l2 # L2손실 하이퍼 파라미터\n",
    "\n",
    "    def forpass(self,x): # 정방향 계산\n",
    "        z = np.dot(x, self.w) + self.b # 예측값 계산(입력 데이터 * 가중치 + 절편)\n",
    "        return z\n",
    "\n",
    "    def backprop(self, x, err): # 역방향 계산\n",
    "        m = len(x) # 그래디언트 크기. len() : 넘파이 배열의 행 크기 반환.\n",
    "        w_grad = np.dot(x.T, err) / m # 가중치에 대한 평균 그래디언트\n",
    "        b_grad = np.sum(err)/m # 절편에 대한 평균 그래디언트\n",
    "        return w_grad, b_grad\n",
    "    \n",
    "    def activation(self, z): # 예측값을 0~1 사이의 값으로 만들어버림.\n",
    "        a = 1/ (1+ np.exp(-z)) # 시그모이드 계산\n",
    "        return a\n",
    "\n",
    "    def fit(self, x, y, epochs = 100, x_val = None, y_val = None):\n",
    "        # 행렬 연산을 위해 변환\n",
    "        y = y.reshape(-1,1) # 열 벡터로 바꿈([ㅁ ㅁ ㅁ ㅁ]^T)\n",
    "        y_val = y_val.reshape(-1,1) # 열 벡터로 바꿈\n",
    "        m = len(x)\n",
    "        #가중치, 절편 초기값 설정\n",
    "        self.w = np.ones((x.shape[1],1)) # 가중치 초기화([1,1,1]^T)\n",
    "        self.b = 0\n",
    "        self.w_history.append(self.w.copy()) # 가중치 기록\n",
    "\n",
    "        # 에포크만큼 반복\n",
    "        for i in range(epochs):\n",
    "            z = self.forpass(x) # 예측값 \n",
    "            a = self.activation(z) # 활성화 함수\n",
    "            err = -(y-a) #실제 값 - 예측값 = 오차\n",
    "            #오차를 역전파하여 그래디언트 계산\n",
    "            w_grad, b_grad = self.backprop(x, err)\n",
    "            #그래디언트에서 페널티 항의 미분값을 더함\n",
    "            w_grad += (self.l1 * np.sign(self.w) + self.l2 * self.w) / m # L1규제, L2규제를 적용해 그래디언트 계산\n",
    "            self.w -= self.lr * w_grad\n",
    "            self.b -= self.lr * b_grad\n",
    "            #가중치 기록\n",
    "            self.w_history.append(self.w.copy())\n",
    "            # 클리핑(역전파 과정에서 그래디언트가 비정상적으로 작아지거나 커지는거 방지)\n",
    "            a = np.clip(a, 1e-10, 1-1e-10)\n",
    "            # 로그 손실과 규제 손실을 더하여 리스트에 추가\n",
    "            loss = np.sum(-(y*np.log(a) + (1-y)*np.log(1-a)))\n",
    "            self.losses.append((loss+self.reg_loss())/m) # 평균 손실\n",
    "            # 검증 세트에 대한 손실 계산\n",
    "            self.update_val_loss(x_val, y_val)\n",
    "\n",
    "    def predict(self,x):\n",
    "        z = self.forpass(x)\n",
    "        return z>0\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        # 예측값, 타깃 값 비교해 True의 비율 반환\n",
    "        return np.mean(self.predict(x) == y.reshape(-1,1))\n",
    "    \n",
    "    def reg_loss(self):\n",
    "        # 가중치에 규제 적용\n",
    "        return self.l1 * np.sum(np.abs(self.w)) + self.l2 / 2 * np.sum(self.w**2)\n",
    "\n",
    "    # 검증 세트에 대한 손실 계산\n",
    "    def update_val_loss(self, x_val, y_val):\n",
    "        z = self.forpass(x_val) # 정방향 계산\n",
    "        a = self.activation(z) # 활성화 함수\n",
    "        a = np.clip(a, 1e-10, 1-1e-10) # 활성화 함수 클리핑\n",
    "        # 로그 손실과 규제 손실을 더하여 리스트에 추가\n",
    "        val_loss = np.sum(-(y_val*np.log(a) + (1-y_val)*np.log(1-a)))\n",
    "        self.losses.append((val_loss+self.reg_loss())/ len(y_val)) # 평균 손실"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단일 레이어를 상속받은 DualLayer\n",
    "class DualLayer(SingleLayer): # 상속이 안된다. 왜지?\n",
    "\n",
    "    def __init__(self, units = 10, learning_rate = 0.1, l1 = 0, l2 = 0): # 파이썬은 __init__에서 변수 선언. 항상 신기한 부분이다.\n",
    "        self.units = units # 은닉층의 뉴런 개수\n",
    "        # 가중치랑 절편\n",
    "        self.w1 = None \n",
    "        self.b1 = None\n",
    "        self.w2 = None\n",
    "        self.b2 = None\n",
    "        self.a1 = None # 은닉층의 활성화 출력\n",
    "        self.losses = [] # 훈련 손실\n",
    "        self.val_losses = [] # 검증 손실\n",
    "        self.lr = learning_rate # 학습률\n",
    "        self.l1 = l1 # L1 손실 하이퍼파라미터\n",
    "        self.l2 = l2 # L2 손실 하이퍼파라미터\n",
    "    \n",
    "    def forpass(self, x):# 정방향 계산\n",
    "        z1 = np.dot(x, self.w1) + self.b1 # 첫 번째 층에서 출력 계산\n",
    "        self.a1 = self.activation(z1) # 활성화 함수(activation 함수는 SingleLayer에서 가져온 것)\n",
    "        z2 = np.dot(self.a1, self.w2) + self.b2 # 두 번째 층에서 출력 계산(첫 번째 층의 활성화 함수 출력값 * 두번 째 층의 가중치 + 절편)\n",
    "        return z2\n",
    "    \n",
    "    def backprop(self, x, err): # 역방향 계산\n",
    "        m = len(x) # 입력 데이터 개수\n",
    "        \n",
    "        # 출력층의 가중치, 절편에 대한 공식\n",
    "        w2_grad = np.dot(self.a1.T, err) / m # 출력층의 가중치에 대한 그래디언트 계산(행렬 연산의 그래디언트 -> Transpose한 행렬과 오차를 계산하면 됨)\n",
    "        b2_grad = np.sum(err)/m # 절편에 대한 그래디언트\n",
    "        # 손실 함수(시그모이드 함수)도 그래디언트 계산\n",
    "        err_to_hidden = np.dot(err, self.w2.T) * self.a1 * (1 - self.a1) # 은닉층의 그래디언트를 쉽게 계산하기 위해 미리 계산해놓은 것.\n",
    "        # 은닉충의 가중치와 절편에 대한 그래디언트 계산\n",
    "\n",
    "        # 첫번 째 층의 그래디언트\n",
    "        w1_grad = np.dot(x.T, err_to_hidden) / m\n",
    "        b1_grad = np.sum(err_to_hidden, axis=0)/ m\n",
    "\n",
    "        return w1_grad, b1_grad, w2_grad, b2_grad\n",
    "\n",
    "    # fit()을 3개로 나눔(init_weights, fit, training)\n",
    "    # 1. 은닉층, 출력층의 가중치와 절편을 초기화\n",
    "    # 2. 에포크마다 정방햐 계산\n",
    "    # 3. 오차를 역전파 가중치, 절편의 그래디언트를 계산\n",
    "    # 4. 손실을 계산하여 누적\n",
    "    def init_weights(self, n_features):\n",
    "        self.w1 = np.ones((n_features, self.units)) # (특성 개수, 은닉층 크기) 만큼의 배열을 생성(모든 원소가 1)\n",
    "        self.b1 = np.zeros(self.units) # (은닉층 크기, 1) 만큼의 배열 생성\n",
    "        self.w2 = np.ones((self.units, 1)) # (특성, 1) 크기의 배열 생성\n",
    "        self.b2 = 0\n",
    "    def fit(self, x, y, epochs = 100, x_val = None, y_val = None):\n",
    "        # 초기화 파트\n",
    "        y = y.reshape(-1, 1) # 타깃을 열 벡터(위아래로 긴거)로 바꿈\n",
    "        y_val = y_val.reshape(-1, 1)\n",
    "        m = len(x) # 데이터셋 개수\n",
    "        self.init_weights(x.shape[1]) # 은닉층과 출력층의 가중치를 초기화\n",
    "        # 에포크만큼 반복(훈련 파트)\n",
    "        for i in range(epochs):\n",
    "            a = self.training(x, y, m) # 정방향, 역방향 계산을 수행. 출력값으로 마지막 활성화 함수의 출력을 반환\n",
    "            a = np.clip(a, 1e-10, 1-1e-10) # 클리핑. 이렇게 해야 활성화 값이 튀겨서 계산에 지장이 생기는 일을 방지할 수 있다. \n",
    "            loss = np.sum(-(y*np.log(a) + (1-y)*np.log(1-a))) # log손실\n",
    "            self.losses.append((loss + self.reg_loss()) / m) # log손실과 규제 손실(reg_loss)을 더한 걸 리스트에 추가\n",
    "            # 검증 세트에 대한 손실을 계산\n",
    "            self.update_val_loss(x_val, y_val)\n",
    "    # 계산 파트(정방향 계산, 역방향 계산)\n",
    "    def training(self, x, y, m):\n",
    "        z = self.forpass(x) # 출력\n",
    "        a = self.activation(z) # 활성화 함수\n",
    "        err = -(y-a) # 오차\n",
    "\n",
    "        #역전파로 그래디언트 계산\n",
    "        w1_grad, b1_grad, w2_grad, b2_grad = self.backprop(x, err)\n",
    "        # 그래디언트에서 규제 적용(패널티 항의 미분값 빼기)\n",
    "        w1_grad += (self.l1 * np.sign(self.w1) + self.l2 * self.w1) / m\n",
    "        w2_grad += (self.l1 * np.sign(self.w2) + self.l2 * self.w2) / m\n",
    "\n",
    "        #은닉층의 가중치, 절편 업데이트\n",
    "        self.w1 -= self.lr * w1_grad\n",
    "        self.b1 -= self.lr * b1_grad\n",
    "        #출력층의 가중치, 절편 업데이트\n",
    "        self.w2 -= self.lr * w2_grad\n",
    "        self.b2 -= self.lr * b2_grad\n",
    "\n",
    "        return a\n",
    "    \n",
    "    def reg_loss(self):\n",
    "        return self.l1 * (np.sum(np.abs(self.w1)) + np.sum(np.abs(self.w2))) + \\\n",
    "            self.l2 / 2 * (np.sum(self.w1**2) + np.sum(self.w2**2)) # **:나머지\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치의 초기값을 1이 아닌 정규 분포를 따르는 무작위 수로 초기화\n",
    "\n",
    "class RandomInitNetwork(DualLayer):\n",
    "    def init_weights(self, n_features): # 가중치, 절편 초기화 함수 재정의\n",
    "        np.random.seed(42) # 예제에서 이 방식이 통한다는걸 보여주기 위해 랜덤값을 고정시켰으나 실제로는 그럴 필요가 없다. \n",
    "        self.w1 = np.random.normal(0, 1, (n_features, self.units)) # normal(평균, 표준편차, 배열 크기). 정규분포에 근거해 난수를 생성\n",
    "        self.b1 = np.zeros(self.units)\n",
    "        self.w2 = np.random.normal(0, 1, (self.units, 1))\n",
    "        self.b2 = 0"
   ]
  },
  {
   "source": [
    "# 미니 배치 경사 하강법 적용"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미니 배치 경사 하강법을 적용한 모델\n",
    "# 전체 데이터셋을 n등분 후 각 등분된 모델(미니 배치) 단위로 훈련 수행. 확률적 경사 하강법(하나씩 훈련하고 가중치, 절편 반영)과 배치 경사 하강법(전체 다 훈련하고 가중치, 절편 반영)의 중간 단계.\n",
    "# 그래서 확률적 방식과 배치 방식의 장점, 단점을 모두 가진다. 얼마나 가질지는 미니 배치의 단위(batch_size)로 내가 알아서 조절해야함.( = batch_size는 하이퍼 파라미터)\n",
    "\n",
    "class MinibatchNetwork(RandomInitNetwork):\n",
    "    def __init__(self, units = 10, batch_size = 32, learning_rate = 0.1, l1 = 0, l2 = 0):\n",
    "        super().__init__(units, learning_rate, l1, l2) # 부모 클래스 초기화\n",
    "        self.batch_size = batch_size\n",
    "    def fit(self, x, y, epochs = 100, x_val = None, y_val = None):\n",
    "        # 초기화 파트\n",
    "        y = y.reshape(-1, 1) # 타깃을 열 벡터(위아래로 긴거)로 바꿈\n",
    "        self.init_weights(x.shape[1]) # 은닉층과 출력층의 가중치를 초기화\n",
    "        np.random.seed(42) # 교재에서 예제와 같음을 보여주기 위해 사용한 함수. 실제로는 사용하지 않아도 된다. \n",
    "\n",
    "        # 에포크만큼 반복(훈련 파트)\n",
    "        for i in range(epochs):\n",
    "            loss = 0\n",
    "            # 미니 배치를 순환하는 for문\n",
    "            for x_batch, y_batch in self.gen_batch(x, y): # gen_batch() : 전체 데이터를 받아 batch_size의 크기를 갖는 미니 배치를 만들어 반환\n",
    "                y_batch = y_batch.reshape(-1,1) # 열 행렬로 변환 \n",
    "                m = len(x_batch) # 배치 사이즈 크기\n",
    "                a = self.training(x_batch, y_batch, m) # 미니 배치 단위로 정방향, 역방향 계산을 수행. 출력값으로 마지막 활성화 함수의 출력을 반환\n",
    "                a = np.clip(a, 1e-10, 1-1e-10) # 클리핑. 이렇게 해야 활성화 값이 튀겨서 계산에 지장이 생기는 일을 방지할 수 있다. \n",
    "                loss += np.sum(-(y_batch*np.log(a) + (1-y_batch)*np.log(1-a))) # 각 미니배치마다 발생하는 log손실과 규제 손실(reg_loss)을 차곡차곡 쌓음.\n",
    "            self.losses.append((loss + self.reg_loss()) / len(x)) # 모은 뒤 평균값 구함.\n",
    "            # 검증 세트에 대한 손실을 계산\n",
    "            self.update_val_loss(x_val, y_val)\n",
    "\n",
    "    def gen_batch(self, x, y):\n",
    "        length = len(x)\n",
    "        bins = length // self.batch_size # 미니 배치가 몇개 있는가? (//연산자는 '몫'을 의미)\n",
    "        if length % self.batch_size : # 몫으로 나누고 나머지 값이 있으면 \n",
    "            bins +=1 # 1 추가. 왜냐하면 배치사이즈로 데이터 나누고 남은 값을 버릴 수는 없으니\n",
    "        indexes = np.random.permutation(np.arange(len(x))) # 인덱스를 섞음. x길이만큼 생성된 [0, 1, 2, ...] 배열을 셔플한 걸 반환\n",
    "        #이 코드를 왜 쓰는거지? ======\n",
    "        x = x[indexes]\n",
    "        y = y[indexes]\n",
    "        #이 코드를 왜 쓰는거지? ======\n",
    "        for i in range(bins):\n",
    "            start = self.batch_size*i\n",
    "            end = self.batch_size*(i+1)\n",
    "            yield x[start:end], y[start:end] # yield : 반환 방식. 큰 데이터를 한 번만 반환함. 이게 뭔 뜻이냐면 전체 데이터셋 중 index의 범위가 start~end에 해당하는 배열의 일부분을 반환한다는 뜻이다. 이 때 start~end의 범위는 batch_size의 크기와 같다. 매번 포문을 진행할 때마다 batch_size크기에 해당하는 미니 배치들을 처음 데이터부터 마지막 데이터까지 순서대로 뽑아내서 반환하고 이를 이용해 훈련을 시킨다는 거다. \n"
   ]
  },
  {
   "source": [
    "# 다중 분류 신경망 구현"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinibatchNetwork에 다중 분류 기능을 추가. 다중 분류의 경사 하강법 알고리즘은 이진 분류의 경사 하강법 알고리즘과 원리는 같고 소프트맥스 함수가 추가된 점만 다르다.\n",
    "class MultiClassNetwork(MinibatchNetwork):\n",
    "    # 활성화 함수를 시그모이드 함수로\n",
    "    def sigmoid(self,z):\n",
    "        a = 1/(1+np.exp(-z)) # 시그모이드 계산\n",
    "        return a\n",
    "    # 소프트맥스 함수\n",
    "    def softmax(self, z):\n",
    "        exp_z = np.exp(z) # z(출력값)을 모두 지수로 만들어줌.(z -> e^z)\n",
    "        return exp_z / np.sum(exp_z, axis = 1).reshape(-1,1) # 소프트맥스 함수는 정규화 함수므로 전체에 대한 비율?인 값으로 반환. 계산을 위해 열 백터로 변환\n",
    "\n",
    "    def init_weights(self, n_features, n_classes): # 다중 분류 방식이므로 w2의 크기를 (은닉층의 크기, 클래스 개수)로 설정해야한다. 이 때 클래스 개수는 분류할 가짓수 (ex : 자동차, 배, 비행기면 클래스가 3개)의 갯수와 같다.  \n",
    "        np.random.seed(42) # 예제에서 이 방식이 통한다는걸 보여주기 위해 랜덤값을 고정시켰으나 실제로는 그럴 필요가 없다. \n",
    "        self.w1 = np.random.normal(0, 1, (n_features, self.units)) # 정규 분포에 근거한 난수로 (은닉층의 크기, 클래스 개수) 크기의 배열 생성\n",
    "        self.b1 = np.zeros(self.units)\n",
    "        self.w2 = np.random.normal(0, 1, (self.units, n_classes))\n",
    "        self.b2 = np.zeros(n_classes)\n",
    "\n",
    "    def forpass(self, x):# 정방향 계산. 활성화 함수로 시그모이드 함수를 써야하므로 재정의 한다. \n",
    "        z1 = np.dot(x, self.w1) + self.b1 \n",
    "        self.a1 = self.sigmoid(z1) # 활성화 함수 적용 \n",
    "        z2 = np.dot(self.a1, self.w2) + self.b2 # 두 번째 층에서 출력 계산(첫 번째 층의 활성화 함수 출력값 * 두번 째 층의 가중치 + 절편)\n",
    "        return z2\n",
    "\n",
    "    # fit() 재정의. init_weights()를 호출할 때 클래스의 개수를 매개변수의 값으로 넘겨줌.\n",
    "    def fit(self, x, y, epochs = 100, x_val = None, y_val = None):\n",
    "        # 초기화 파트\n",
    "        np.random.seed(42) # 교재에서 예제와 같음을 보여주기 위해 사용한 함수. 실제로는 사용하지 않아도 된다. \n",
    "        self.init_weights(x.shape[1], y.shape[1]) # 은닉층과 출력층의 가중치를 초기화\n",
    "\n",
    "        # 에포크만큼 반복(훈련 파트)\n",
    "        for i in range(epochs):\n",
    "            loss = 0\n",
    "            print('.', end='')# 훈련의 진행 상황을 알아보기 위해 에포크마다 '.'이 출력되게끔 한다. \n",
    "            for x_batch, y_batch in self.gen_batch(x, y): # 미니 배치마다 훈련\n",
    "                a = self.training(x_batch, y_batch)\n",
    "                # print(a) # 왜 None이라고 뜨지? <- return a를 하지 않았기 때문.\n",
    "                a = np.clip(a, 1e-10, 1-1e-10) # 클리핑\n",
    "                loss +=np.sum(-y_batch*np.log(a))# 로그 손실 \n",
    "            self.losses.append((loss + self.reg_loss()) / len(x)) # 로그 손실 + 규제 손실 더해서 리스트에 추가\n",
    "            self.update_val_loss(x_val, y_val) # 검증 세트에 대한 손실 계산\n",
    "    \n",
    "    # 재정의\n",
    "    def training(self, x, y):\n",
    "        m = len(x)\n",
    "        z = self.forpass(x)\n",
    "        # print(\"z : \", z)\n",
    "        a = self.softmax(z) # 활성화 함수를 softmax()로 변경\n",
    "\n",
    "        err = -(y-a) # 오차\n",
    "\n",
    "        #역전파로 그래디언트 계산\n",
    "        w1_grad, b1_grad, w2_grad, b2_grad = self.backprop(x, err)\n",
    "        # 그래디언트에서 규제 적용(패널티 항의 미분값 빼기)\n",
    "        w1_grad += (self.l1 * np.sign(self.w1) + self.l2 * self.w1) / m\n",
    "        w2_grad += (self.l1 * np.sign(self.w2) + self.l2 * self.w2) / m\n",
    "\n",
    "        #은닉층의 가중치, 절편 업데이트\n",
    "        self.w1 -= self.lr * w1_grad\n",
    "        self.b1 -= self.lr * b1_grad\n",
    "        #출력층의 가중치, 절편 업데이트\n",
    "        self.w2 -= self.lr * w2_grad\n",
    "        self.b2 -= self.lr * b2_grad\n",
    "        return a\n",
    "\n",
    "    # predict 함수에서는 결과값만으로 실제값과 비교(=활성화 함수를 거칠 필요가 없음.)\n",
    "    def predict(self, x):\n",
    "        z = self.forpass(x)\n",
    "        return np.argmax(z, axis = 1) # 가장 큰 값의 인덱스(=가장 높은 확률로 인식된 것의 인덱스 반환)\n",
    "\n",
    "    # 예측값과 실제값의 클래스 비교   \n",
    "    def score(self, x, y):\n",
    "        # 예측과 타깃 열 벡터를 비교하여 True의 비율 반환\n",
    "        return np.mean(self.predict(x) == np.argmax(y, axis = 1))\n",
    "\n",
    "    def update_val_loss(self, x_val, y_val):\n",
    "        z = self.forpass(x_val)\n",
    "        a = self.softmax(z)\n",
    "        a = np.clip(a, 1e-10, 1-1e-10)\n",
    "\n",
    "        val_loss = np.sum(-y_val * np.log(a)) # 로그 손실\n",
    "        self.val_losses.append((val_loss + self.reg_loss()) / len(y_val)) # 로그 손실 + 규제 손실을 더해 리스트에 추가"
   ]
  },
  {
   "source": [
    "# 훈련하기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "........................................"
     ]
    }
   ],
   "source": [
    "fc= MultiClassNetwork(units=100, batch_size=256)\n",
    "fc.fit(x_train, y_train_encoded, x_val = x_val, y_val = y_val_encoded, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"262.19625pt\" version=\"1.1\" viewBox=\"0 0 392.14375 262.19625\" width=\"392.14375pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2020-12-31T20:32:07.162054</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 262.19625 \nL 392.14375 262.19625 \nL 392.14375 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 50.14375 224.64 \nL 384.94375 224.64 \nL 384.94375 7.2 \nL 50.14375 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m5db51b8b79\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"65.361932\" xlink:href=\"#m5db51b8b79\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(62.180682 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"104.382911\" xlink:href=\"#m5db51b8b79\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <g transform=\"translate(101.201661 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"143.40389\" xlink:href=\"#m5db51b8b79\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 10 -->\n      <g transform=\"translate(137.04139 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"182.424869\" xlink:href=\"#m5db51b8b79\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 15 -->\n      <g transform=\"translate(176.062369 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"221.445848\" xlink:href=\"#m5db51b8b79\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 20 -->\n      <g transform=\"translate(215.083348 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"260.466827\" xlink:href=\"#m5db51b8b79\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 25 -->\n      <g transform=\"translate(254.104327 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"299.487806\" xlink:href=\"#m5db51b8b79\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 30 -->\n      <g transform=\"translate(293.125306 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"338.508785\" xlink:href=\"#m5db51b8b79\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 35 -->\n      <g transform=\"translate(332.146285 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"377.529764\" xlink:href=\"#m5db51b8b79\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 40 -->\n      <g transform=\"translate(371.167264 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- iteration -->\n     <g transform=\"translate(196.421094 252.916562)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n       <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n       <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n       <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n       <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n       <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n       <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"66.992188\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"128.515625\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"169.628906\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"230.908203\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"270.117188\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"297.900391\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"359.082031\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m780caad83f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m780caad83f\" y=\"214.82651\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.50 -->\n      <g transform=\"translate(20.878125 218.625729)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m780caad83f\" y=\"187.831885\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.75 -->\n      <g transform=\"translate(20.878125 191.631104)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m780caad83f\" y=\"160.83726\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.00 -->\n      <g transform=\"translate(20.878125 164.636479)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m780caad83f\" y=\"133.842635\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 1.25 -->\n      <g transform=\"translate(20.878125 137.641854)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m780caad83f\" y=\"106.84801\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 1.50 -->\n      <g transform=\"translate(20.878125 110.647229)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m780caad83f\" y=\"79.853385\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 1.75 -->\n      <g transform=\"translate(20.878125 83.652604)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m780caad83f\" y=\"52.85876\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 2.00 -->\n      <g transform=\"translate(20.878125 56.657978)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m780caad83f\" y=\"25.864135\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 2.25 -->\n      <g transform=\"translate(20.878125 29.663353)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_19\">\n     <!-- loss -->\n     <g transform=\"translate(14.798438 125.577812)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n       <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"88.964844\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"141.064453\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_18\">\n    <path clip-path=\"url(#p7ae153e234)\" d=\"M 65.361932 17.083636 \nL 73.166128 146.85315 \nL 80.970323 165.950341 \nL 88.774519 175.522476 \nL 96.578715 181.617326 \nL 104.382911 186.005527 \nL 112.187107 189.316578 \nL 119.991302 191.938379 \nL 127.795498 194.104815 \nL 135.599694 195.968077 \nL 143.40389 197.685298 \nL 151.208086 199.185025 \nL 159.012281 200.494474 \nL 166.816477 201.587555 \nL 174.620673 202.651245 \nL 182.424869 203.620158 \nL 190.229065 204.446239 \nL 198.03326 205.252432 \nL 205.837456 205.982594 \nL 213.641652 206.604876 \nL 221.445848 207.277814 \nL 229.250044 207.889675 \nL 237.05424 208.464175 \nL 244.858435 208.979363 \nL 252.662631 209.465922 \nL 260.466827 209.950702 \nL 268.271023 210.392574 \nL 276.075219 210.811703 \nL 283.879414 211.211138 \nL 291.68361 211.608286 \nL 299.487806 211.969391 \nL 307.292002 212.361226 \nL 315.096198 212.680111 \nL 322.900393 213.012152 \nL 330.704589 213.336609 \nL 338.508785 213.633046 \nL 346.312981 213.949533 \nL 354.117177 214.245711 \nL 361.921372 214.501594 \nL 369.725568 214.756364 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path clip-path=\"url(#p7ae153e234)\" d=\"M 65.361932 128.832996 \nL 73.166128 159.256734 \nL 80.970323 170.931508 \nL 88.774519 178.62597 \nL 96.578715 183.364872 \nL 104.382911 186.935882 \nL 112.187107 189.883552 \nL 119.991302 192.325896 \nL 127.795498 193.873344 \nL 135.599694 195.770879 \nL 143.40389 197.528883 \nL 151.208086 198.818304 \nL 159.012281 200.03993 \nL 166.816477 201.009032 \nL 174.620673 201.592801 \nL 182.424869 202.772287 \nL 190.229065 203.558073 \nL 198.03326 204.325879 \nL 205.837456 204.941525 \nL 213.641652 205.554583 \nL 221.445848 206.019225 \nL 229.250044 206.681269 \nL 237.05424 207.0656 \nL 244.858435 207.611551 \nL 252.662631 207.823921 \nL 260.466827 208.52513 \nL 268.271023 208.870419 \nL 276.075219 209.204045 \nL 283.879414 209.551337 \nL 291.68361 210.041171 \nL 299.487806 210.219085 \nL 307.292002 210.63695 \nL 315.096198 210.865388 \nL 322.900393 211.10594 \nL 330.704589 211.440409 \nL 338.508785 211.62696 \nL 346.312981 211.916495 \nL 354.117177 212.243307 \nL 361.921372 212.255444 \nL 369.725568 212.545345 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 50.14375 224.64 \nL 50.14375 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 384.94375 224.64 \nL 384.94375 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 50.14375 224.64 \nL 384.94375 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 50.14375 7.2 \nL 384.94375 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 298.353125 45.1125 \nL 377.94375 45.1125 \nQ 379.94375 45.1125 379.94375 43.1125 \nL 379.94375 14.2 \nQ 379.94375 12.2 377.94375 12.2 \nL 298.353125 12.2 \nQ 296.353125 12.2 296.353125 14.2 \nL 296.353125 43.1125 \nQ 296.353125 45.1125 298.353125 45.1125 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_20\">\n     <path d=\"M 300.353125 20.298437 \nL 320.353125 20.298437 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_21\"/>\n    <g id=\"text_20\">\n     <!-- train_loss -->\n     <g transform=\"translate(328.353125 23.798437)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 50.984375 -16.609375 \nL 50.984375 -23.578125 \nL -0.984375 -23.578125 \nL -0.984375 -16.609375 \nz\n\" id=\"DejaVuSans-95\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"232.763672\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"282.763672\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"310.546875\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"371.728516\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"423.828125\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n    <g id=\"line2d_22\">\n     <path d=\"M 300.353125 35.254687 \nL 320.353125 35.254687 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_23\"/>\n    <g id=\"text_21\">\n     <!-- val_loss -->\n     <g transform=\"translate(328.353125 38.754687)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 8.796875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nL 35.6875 0 \nL 23.484375 0 \nz\n\" id=\"DejaVuSans-118\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-118\"/>\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"198.242188\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"226.025391\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"287.207031\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"339.306641\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p7ae153e234\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"50.14375\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.plot(fc.losses)\n",
    "plt.plot(fc.val_losses)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iteration')\n",
    "plt.legend(['train_loss', 'val_loss'])\n",
    "plt.show()\n",
    "\n",
    "# 훈련 모델 점수 비교. 초반에 빠르게 감소 -> 수렴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8150833333333334"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "fc.score(x_val, y_val_encoded) # 점수 확인. 텐서플로우로 만들면 더 정확한 모델을 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 분류를 위한 모델 제작 과정을 정리해보자. \n",
    "# 1. 데이터를 전처리 한다. 전체 데이터 세트를 훈련 세트와 테스트 세트로 나누고 훈련 세트를 다시 훈련 세트와 검증 세트로 나눈다. 이 때 다중 분류를 해야하니 답변 데이터(타깃 데이터)를 [0,0,...1,0,..]꼴의 n개의 클래스에 대한 n열 벡터로 만들어주자. 이를 원-핫 인코딩(one-hot encoding)이라고 한다. \n",
    "# 2. 모델을 만든다. 이 때 모델에 각 레이어에 대한 가중치가 다 들어있어야 한다.(w1, w2, b1, b2, a1, a2 ,...a). 얘들은 당연히 벡터다. a1, a2, ...는 은닉층의 활성화 함수 값이고 최후의 활성화 함수 출력값(답 결정을 담당하는 값)은 a다. \n",
    "# 이 때 당연한 말이지만 역방향 계산으로 각 레이어의 가중치, 절편을 모두 수정해야한다. \n",
    "# 초기화(init), 훈련(fit, training), 검증(score)의 3개의 파트로 나눠서 모델을 만들면 된다. \n",
    "# 3. 훈련 시키기. 객체 초기화 후 fit()으로 훈련을 시키자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}